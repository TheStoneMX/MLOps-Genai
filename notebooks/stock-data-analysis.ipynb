{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Stocks Data Analysis\n",
    "\n",
    "This notebook analyzes the S&P 500 stocks dataset to visualize its characteristics, identify class imbalances, and detect any anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 619040 entries, 0 to 619039\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   date    619040 non-null  object \n",
      " 1   open    619029 non-null  float64\n",
      " 2   high    619032 non-null  float64\n",
      " 3   low     619032 non-null  float64\n",
      " 4   close   619040 non-null  float64\n",
      " 5   volume  619040 non-null  int64  \n",
      " 6   Name    619040 non-null  object \n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 33.1+ MB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "         date   open   high    low  close    volume Name\n",
      "0  2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
      "1  2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
      "2  2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
      "3  2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
      "4  2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL\n",
      "\n",
      "Basic statistics:\n",
      "                open           high            low          close  \\\n",
      "count  619029.000000  619032.000000  619032.000000  619040.000000   \n",
      "mean       83.023334      83.778311      82.256096      83.043763   \n",
      "std        97.378769      98.207519      96.507421      97.389748   \n",
      "min         1.620000       1.690000       1.500000       1.590000   \n",
      "25%        40.220000      40.620000      39.830000      40.245000   \n",
      "50%        62.590000      63.150000      62.020000      62.620000   \n",
      "75%        94.370000      95.180000      93.540000      94.410000   \n",
      "max      2044.000000    2067.990000    2035.110000    2049.000000   \n",
      "\n",
      "             volume  \n",
      "count  6.190400e+05  \n",
      "mean   4.321823e+06  \n",
      "std    8.693610e+06  \n",
      "min    0.000000e+00  \n",
      "25%    1.070320e+06  \n",
      "50%    2.082094e+06  \n",
      "75%    4.284509e+06  \n",
      "max    6.182376e+08  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/all_stocks_5yr.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "date       0\n",
      "open      11\n",
      "high       8\n",
      "low        8\n",
      "close      0\n",
      "volume     0\n",
      "Name       0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned dataset shape: (619040, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "print(missing_values)\n",
    "print(\"\\nCleaned dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset shape: (619029, 7)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "print(\"\\nCleaned dataset shape:\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the 'date' column to datetime objects.\n",
    "# Uses errors='coerce' to handle invalid parsing; invalid dates become NaT.\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops rows where 'date' conversion failed.\n",
    "# Ensures that all entries have valid dates.\n",
    "df = df.dropna(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminates any duplicate rows to prevent skewed calculations.\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data saved to ../data/clean_stocks_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "output_file = \"../data/clean_stocks_data.csv\"\n",
    "df_cleaned.to_csv(output_file, index=False)\n",
    "print(f\"\\nCleaned data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Class Distribution (Stock Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stocks: 505\n",
      "Average number of data points per stock: 1225.82\n",
      "Minimum number of data points: 44\n",
      "Maximum number of data points: 1259\n"
     ]
    }
   ],
   "source": [
    "# Count the number of data points for each stock\n",
    "stock_counts = df['Name'].value_counts()\n",
    "\n",
    "# Print some statistics about the distribution\n",
    "print(f\"Number of unique stocks: {len(stock_counts)}\")\n",
    "print(f\"Average number of data points per stock: {stock_counts.mean():.2f}\")\n",
    "print(f\"Minimum number of data points: {stock_counts.min()}\")\n",
    "print(f\"Maximum number of data points: {stock_counts.max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
